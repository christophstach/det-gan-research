{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_id = \"0b6dd99c-b9d9-45d8-978e-1fac4373bbeb\"\n",
    "os.chdir(f\"/home/christoph/Code/det-gan-research/checkpoints/{checkpoint_id}/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import utils\n",
    "\n",
    "from ipywidgets import Video\n",
    "from tqdm.notebook import tqdm\n",
    "from determined.experimental import Checkpoint\n",
    "from models import MsgGenerator\n",
    "from msg_gan import MsgGANTrail\n",
    "from metrics import InceptionScore\n",
    "\n",
    "from distributions import TruncatedNormal\n",
    "\n",
    "toPILImage = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring unexpected nvidia-smi output: [\"NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\"]\n",
      "WARNING:root:Ignoring unexpected nvidia-smi output: []\n",
      "WARNING:root:`nvidia-smi` exited with failure status code 9\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-353a46a78ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/det-gan-research/.venv/lib/python3.7/site-packages/determined_common/experimental/checkpoint/_checkpoint.py\u001b[0m in \u001b[0;36mload_from_path\u001b[0;34m(path, tags, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             return determined_common.experimental.checkpoint._torch.load_model(\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             )\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/det-gan-research/.venv/lib/python3.7/site-packages/determined_common/experimental/checkpoint/_torch.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(ckpt_dir, metadata, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtrial_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPyTorchTrialContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPyTorchTrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_state_dict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Backward compatible with older checkpoint format.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/det-gan-research/checkpoints/0b6dd99c-b9d9-45d8-978e-1fac4373bbeb/code/msg_gan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    112\u001b[0m         self.inception_score_metric = InceptionScore(\n\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_per_slot_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         )\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_classes'"
     ]
    }
   ],
   "source": [
    "trail = Checkpoint.load_from_path(\"../\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 6\n",
    "truncations=(-1.25, 1.25)\n",
    "noise_size = trail.latent_dimension\n",
    "z = utils.sample_noise(num_images, noise_size, truncations=truncations)\n",
    "dist = utils.sample_noise(1, 100000, truncations=truncations).squeeze()\n",
    "\n",
    "ax = sns.displot(dist, bins=np.arange(-4, 4, 0.25), kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, w = trail.generator(z)\n",
    "biggest_size = images[-1].shape[-1]\n",
    "num_resolutions = int(math.log2(biggest_size))\n",
    "\n",
    "resolutions, x = trail.generator(z)\n",
    "fig, axes = plt.subplots(nrows=num_images, ncols=num_resolutions - 1, dpi=200, figsize=(6, 6))\n",
    "\n",
    "for col, resolution in enumerate(resolutions):\n",
    "    resolution = utils.shift_image_range(resolution)\n",
    "    for row, tensor in enumerate(resolution):        \n",
    "        image = toPILImage(tensor.cpu())\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].get_xaxis().set_visible(False)\n",
    "        axes[row, col].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model, resize_to, num_classes = utils.create_evaluation_model(\"default\")\n",
    "\n",
    "inception_score = InceptionScore(eval_model, resize_to, num_classes)\n",
    "z = utils.sample_noise(64, noise_size, truncations=truncations)\n",
    "\n",
    "\n",
    "images, _ = trail.generator(z)\n",
    "inception_score.images = images[-1]\n",
    "inception_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"temp\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "video_path = 'temp/interpolation.mp4'\n",
    "\n",
    "\n",
    "time = 30\n",
    "fps = 30\n",
    "smoothing = 1.25\n",
    "total_frames = time * fps\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "video = cv2.VideoWriter(video_path, fourcc=fourcc, fps=fps, frameSize=(biggest_size, biggest_size))\n",
    "\n",
    "all_z = utils.sample_noise(total_frames, noise_size, normalize=False, truncations=truncations)\n",
    "all_z = scipy.ndimage.gaussian_filter(all_z, [smoothing * fps, 0])\n",
    "all_z = torch.from_numpy(all_z)\n",
    "\n",
    "for idx, z in tqdm(enumerate(all_z), desc=\"Generating video\", total=total_frames):\n",
    "    frame = idx + 1\n",
    "    z.unsqueeze_(dim=0)\n",
    "    tensors, w = trail.generator(z)\n",
    "    tensor = tensors[-1].squeeze()\n",
    "    tensor = utils.shift_image_range(tensor)\n",
    "    \n",
    "    image = toPILImage(tensor.cpu())\n",
    "    image = np.array(image)\n",
    "    image = image[:, :, ::-1].copy() \n",
    "\n",
    "    video.write(image)\n",
    "    \n",
    "video.release()\n",
    "Video.from_file(video_path, play=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
