{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_id = \"2faf2a37-7cc4-4b2c-962d-9df04685d1cd\"\n",
    "os.chdir(f\"/home/christophstach/Code/HTW/det-gan-research/checkpoints/{checkpoint_id}/code/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.ndimage\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import utils\n",
    "\n",
    "from ipywidgets import Video\n",
    "from tqdm.notebook import tqdm\n",
    "from determined.experimental import Checkpoint\n",
    "from models import MsgGenerator\n",
    "from msg_gan import MsgGANTrail\n",
    "from metrics import InceptionScore\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from distributions import TruncatedNormal\n",
    "\n",
    "toPILImage = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MsgDiscriminator:\n\tUnexpected key(s) in state_dict: \"from_rgb_combiners.0.conv.weight\", \"from_rgb_combiners.0.conv.bias\", \"from_rgb_combiners.1.conv.weight\", \"from_rgb_combiners.1.conv.bias\", \"from_rgb_combiners.2.conv.weight\", \"from_rgb_combiners.2.conv.bias\", \"from_rgb_combiners.3.conv.weight\", \"from_rgb_combiners.3.conv.bias\". \n\tsize mismatch for blocks.1.conv1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for blocks.1.conv1.weight_orig: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([40, 40, 3, 3]).\n\tsize mismatch for blocks.1.conv1.weight_u: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for blocks.1.conv1.weight_v: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.1.conv2.weight_orig: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 46, 3, 3]).\n\tsize mismatch for blocks.1.conv2.weight_v: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([414]).\n\tsize mismatch for blocks.2.conv1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for blocks.2.conv1.weight_orig: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for blocks.2.conv1.weight_u: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for blocks.2.conv1.weight_v: copying a param with shape torch.Size([1440]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.2.conv2.weight_orig: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([160, 86, 3, 3]).\n\tsize mismatch for blocks.2.conv2.weight_v: copying a param with shape torch.Size([1440]) from checkpoint, the shape in current model is torch.Size([774]).\n\tsize mismatch for blocks.3.conv1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for blocks.3.conv1.weight_orig: copying a param with shape torch.Size([320, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([160, 160, 3, 3]).\n\tsize mismatch for blocks.3.conv1.weight_u: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for blocks.3.conv1.weight_v: copying a param with shape torch.Size([2880]) from checkpoint, the shape in current model is torch.Size([1440]).\n\tsize mismatch for blocks.3.conv2.weight_orig: copying a param with shape torch.Size([320, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([320, 166, 3, 3]).\n\tsize mismatch for blocks.3.conv2.weight_v: copying a param with shape torch.Size([2880]) from checkpoint, the shape in current model is torch.Size([1494]).\n\tsize mismatch for blocks.4.conv1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv1.weight_orig: copying a param with shape torch.Size([640, 641, 3, 3]) from checkpoint, the shape in current model is torch.Size([320, 321, 3, 3]).\n\tsize mismatch for blocks.4.conv1.weight_u: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv1.weight_v: copying a param with shape torch.Size([5769]) from checkpoint, the shape in current model is torch.Size([2889]).\n\tsize mismatch for blocks.4.conv2.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv2.weight_orig: copying a param with shape torch.Size([640, 640, 4, 4]) from checkpoint, the shape in current model is torch.Size([320, 326, 4, 4]).\n\tsize mismatch for blocks.4.conv2.weight_u: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv2.weight_v: copying a param with shape torch.Size([10240]) from checkpoint, the shape in current model is torch.Size([5216]).\n\tsize mismatch for blocks.4.scorer.weight: copying a param with shape torch.Size([1, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 320, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ae27b5987009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/HTW/det-gan-research/.venv/lib/python3.9/site-packages/determined_common/experimental/checkpoint/_checkpoint.py\u001b[0m in \u001b[0;36mload_from_path\u001b[0;34m(path, tags, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mdetermined_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             return determined_common.experimental.checkpoint._torch.load_model(\n\u001b[0m\u001b[1;32m    274\u001b[0m                 \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             )\n",
      "\u001b[0;32m~/Code/HTW/det-gan-research/.venv/lib/python3.9/site-packages/determined_common/experimental/checkpoint/_torch.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(ckpt_dir, metadata, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"models_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/HTW/det-gan-research/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1224\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MsgDiscriminator:\n\tUnexpected key(s) in state_dict: \"from_rgb_combiners.0.conv.weight\", \"from_rgb_combiners.0.conv.bias\", \"from_rgb_combiners.1.conv.weight\", \"from_rgb_combiners.1.conv.bias\", \"from_rgb_combiners.2.conv.weight\", \"from_rgb_combiners.2.conv.bias\", \"from_rgb_combiners.3.conv.weight\", \"from_rgb_combiners.3.conv.bias\". \n\tsize mismatch for blocks.1.conv1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for blocks.1.conv1.weight_orig: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([40, 40, 3, 3]).\n\tsize mismatch for blocks.1.conv1.weight_u: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n\tsize mismatch for blocks.1.conv1.weight_v: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([360]).\n\tsize mismatch for blocks.1.conv2.weight_orig: copying a param with shape torch.Size([80, 80, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 46, 3, 3]).\n\tsize mismatch for blocks.1.conv2.weight_v: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([414]).\n\tsize mismatch for blocks.2.conv1.bias: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for blocks.2.conv1.weight_orig: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([80, 80, 3, 3]).\n\tsize mismatch for blocks.2.conv1.weight_u: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([80]).\n\tsize mismatch for blocks.2.conv1.weight_v: copying a param with shape torch.Size([1440]) from checkpoint, the shape in current model is torch.Size([720]).\n\tsize mismatch for blocks.2.conv2.weight_orig: copying a param with shape torch.Size([160, 160, 3, 3]) from checkpoint, the shape in current model is torch.Size([160, 86, 3, 3]).\n\tsize mismatch for blocks.2.conv2.weight_v: copying a param with shape torch.Size([1440]) from checkpoint, the shape in current model is torch.Size([774]).\n\tsize mismatch for blocks.3.conv1.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for blocks.3.conv1.weight_orig: copying a param with shape torch.Size([320, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([160, 160, 3, 3]).\n\tsize mismatch for blocks.3.conv1.weight_u: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n\tsize mismatch for blocks.3.conv1.weight_v: copying a param with shape torch.Size([2880]) from checkpoint, the shape in current model is torch.Size([1440]).\n\tsize mismatch for blocks.3.conv2.weight_orig: copying a param with shape torch.Size([320, 320, 3, 3]) from checkpoint, the shape in current model is torch.Size([320, 166, 3, 3]).\n\tsize mismatch for blocks.3.conv2.weight_v: copying a param with shape torch.Size([2880]) from checkpoint, the shape in current model is torch.Size([1494]).\n\tsize mismatch for blocks.4.conv1.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv1.weight_orig: copying a param with shape torch.Size([640, 641, 3, 3]) from checkpoint, the shape in current model is torch.Size([320, 321, 3, 3]).\n\tsize mismatch for blocks.4.conv1.weight_u: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv1.weight_v: copying a param with shape torch.Size([5769]) from checkpoint, the shape in current model is torch.Size([2889]).\n\tsize mismatch for blocks.4.conv2.bias: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv2.weight_orig: copying a param with shape torch.Size([640, 640, 4, 4]) from checkpoint, the shape in current model is torch.Size([320, 326, 4, 4]).\n\tsize mismatch for blocks.4.conv2.weight_u: copying a param with shape torch.Size([640]) from checkpoint, the shape in current model is torch.Size([320]).\n\tsize mismatch for blocks.4.conv2.weight_v: copying a param with shape torch.Size([10240]) from checkpoint, the shape in current model is torch.Size([5216]).\n\tsize mismatch for blocks.4.scorer.weight: copying a param with shape torch.Size([1, 640, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 320, 1, 1])."
     ]
    }
   ],
   "source": [
    "trail = Checkpoint.load_from_path(\"../\", map_location=torch.device('cpu'))\n",
    "generator = trail.generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images  = 6\n",
    "truncations = (-2.25, 2.25)\n",
    "noise_size  = trail.latent_dimension\n",
    "num_grid_images = 8 ** 2\n",
    "\n",
    "z = utils.sample_noise(num_images, noise_size, truncations=truncations)\n",
    "dist = utils.sample_noise(1, 100000, truncations=truncations).squeeze()\n",
    "inception_z = utils.sample_noise(128, noise_size, truncations=truncations)\n",
    "grid_z = utils.sample_noise(num_grid_images, noise_size, truncations=truncations)\n",
    "    \n",
    "ax = sns.displot(dist, bins=np.arange(-4, 4, 0.25), kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, w = generator(z)\n",
    "biggest_size = images[-1].shape[-1]\n",
    "num_resolutions = int(math.log2(biggest_size))\n",
    "\n",
    "resolutions, x = generator(z)\n",
    "fig, axes = plt.subplots(nrows=num_images, ncols=num_resolutions - 1, dpi=200, figsize=(6, 6))\n",
    "\n",
    "for col, resolution in enumerate(resolutions):\n",
    "    resolution = utils.shift_image_range(resolution)\n",
    "    for row, tensor in enumerate(resolution):        \n",
    "        image = toPILImage(tensor.cpu())\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].get_xaxis().set_visible(False)\n",
    "        axes[row, col].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_images, _ = generator(grid_z)\n",
    "grid_images = grid_images[-1]\n",
    "grid_images = utils.shift_image_range(grid_images)\n",
    "grid = make_grid(grid_images, nrow=int(math.sqrt(num_grid_images)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16), dpi=200)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.imshow(grid.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model, resize_to, num_classes = utils.create_evaluation_model(\"default\")\n",
    "inception_score = InceptionScore(eval_model, resize_to, num_classes)\n",
    "\n",
    "images, _ = generator(inception_z)\n",
    "inception_score.images = images[-1]\n",
    "inception_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"temp\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "video_path = 'temp/interpolation.mp4'\n",
    "\n",
    "\n",
    "time = 30\n",
    "fps = 30\n",
    "smoothing = 1.25\n",
    "total_frames = time * fps\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "video = cv2.VideoWriter(video_path, fourcc=fourcc, fps=fps, frameSize=(biggest_size, biggest_size))\n",
    "\n",
    "all_z = utils.sample_noise(total_frames, noise_size, truncations=truncations)\n",
    "all_z = scipy.ndimage.gaussian_filter(all_z, [smoothing * fps, 0])\n",
    "all_z = torch.from_numpy(all_z)\n",
    "\n",
    "for idx, z in tqdm(enumerate(all_z), desc=\"Generating video\", total=total_frames):\n",
    "    frame = idx + 1\n",
    "    z.unsqueeze_(dim=0)\n",
    "    tensors, w = generator(z)\n",
    "    tensor = tensors[-1].squeeze()\n",
    "    tensor = utils.shift_image_range(tensor)\n",
    "    \n",
    "    image = toPILImage(tensor.cpu())\n",
    "    image = np.array(image)\n",
    "    image = image[:, :, ::-1].copy() \n",
    "\n",
    "    video.write(image)\n",
    "    \n",
    "video.release()\n",
    "Video.from_file(video_path, play=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
